{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql.functions import monotonically_increasing_id, udf, from_unixtime\n",
    "from pyspark.sql import types as types_\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# files path \n",
    "airport_code_csv = 'airport-codes_csv.csv'\n",
    "us_cities_demographics = 'us-cities-demographics.csv'\n",
    "immigration_data_sample = 'immigration_data_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "airport_code_csv_df = pd.read_csv(airport_code_csv, header=0)\n",
    "us_cities_demographics_df = pd.read_csv(us_cities_demographics, header=0, sep=';')\n",
    "immigration_data_sample_df = pd.read_csv(immigration_data_sample, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_code_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_demographics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(us_cities_demographics_df.iloc[2]['Median Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_data_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "#df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_code_csv_df_spark = spark.read.csv(airport_code_csv, header=True)\n",
    "us_cities_demographics_df_spark = spark.read.option(\"delimiter\", \";\").csv(us_cities_demographics, header=True)\n",
    "immigration_data_sample_df_spark = spark.read.csv(immigration_data_sample, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|ident|type         |name                              |elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|coordinates                          |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "|00A  |heliport     |Total Rf Heliport                 |11          |NA       |US         |US-PA     |Bensalem    |00A     |null     |00A       |-74.93360137939453, 40.07080078125   |\n",
      "|00AA |small_airport|Aero B Ranch Airport              |3435        |NA       |US         |US-KS     |Leoti       |00AA    |null     |00AA      |-101.473911, 38.704022               |\n",
      "|00AK |small_airport|Lowell Field                      |450         |NA       |US         |US-AK     |Anchor Point|00AK    |null     |00AK      |-151.695999146, 59.94919968          |\n",
      "|00AL |small_airport|Epps Airpark                      |820         |NA       |US         |US-AL     |Harvest     |00AL    |null     |00AL      |-86.77030181884766, 34.86479949951172|\n",
      "|00AR |closed       |Newport Hospital & Clinic Heliport|237         |NA       |US         |US-AR     |Newport     |null    |null     |null      |-91.254898, 35.6087                  |\n",
      "+-----+-------------+----------------------------------+------------+---------+-----------+----------+------------+--------+---------+----------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_code_csv_df_spark.printSchema()\n",
    "airport_code_csv_df_spark.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-------------------------+-----+\n",
      "|City            |State        |Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race                     |Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-------------------------+-----+\n",
      "|Silver Spring   |Maryland     |33.8      |40601          |41862            |82463           |1562              |30908       |2.6                   |MD        |Hispanic or Latino       |25924|\n",
      "|Quincy          |Massachusetts|41.0      |44129          |49500            |93629           |4147              |32935       |2.39                  |MA        |White                    |58723|\n",
      "|Hoover          |Alabama      |38.5      |38040          |46799            |84839           |4819              |8229        |2.58                  |AL        |Asian                    |4759 |\n",
      "|Rancho Cucamonga|California   |34.5      |88127          |87105            |175232          |5821              |33878       |3.18                  |CA        |Black or African-American|24437|\n",
      "|Newark          |New Jersey   |34.6      |138040         |143873           |281913          |5829              |86253       |2.73                  |NJ        |White                    |76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_demographics_df_spark.printSchema()\n",
    "us_cities_demographics_df_spark.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|_c0    |cicid    |i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum       |fltno|visatype|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|2027561|4084316.0|2016.0|4.0   |209.0 |209.0 |HHW    |20566.0|1.0    |HI     |20573.0|61.0  |2.0    |1.0  |20160422|null    |null |G      |O      |null   |M      |1955.0 |07202016|F     |null  |JL     |56582674633.0|00782|WT      |\n",
      "|2171295|4422636.0|2016.0|4.0   |582.0 |582.0 |MCA    |20567.0|1.0    |TX     |20568.0|26.0  |2.0    |1.0  |20160423|MTR     |null |G      |R      |null   |M      |1990.0 |10222016|M     |null  |*GA    |94361995930.0|XBLNG|B2      |\n",
      "|589494 |1195600.0|2016.0|4.0   |148.0 |112.0 |OGG    |20551.0|1.0    |FL     |20571.0|76.0  |2.0    |1.0  |20160407|null    |null |G      |O      |null   |M      |1940.0 |07052016|M     |null  |LH     |55780468433.0|00464|WT      |\n",
      "|2631158|5291768.0|2016.0|4.0   |297.0 |297.0 |LOS    |20572.0|1.0    |CA     |20581.0|25.0  |2.0    |1.0  |20160428|DOH     |null |G      |O      |null   |M      |1991.0 |10272016|M     |null  |QR     |94789696030.0|00739|B2      |\n",
      "|3032257|985523.0 |2016.0|4.0   |111.0 |111.0 |CHM    |20550.0|3.0    |NY     |20553.0|19.0  |2.0    |1.0  |20160406|null    |null |Z      |K      |null   |M      |1997.0 |07042016|F     |null  |null   |42322572633.0|LAND |WT      |\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_sample_df_spark.printSchema()\n",
    "immigration_data_sample_df_spark.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")\n",
    "output_path = 'parquet_output/'\n",
    "airport_code_csv_df_spark.write.mode('overwrite').parquet(os.path.join(output_path,'airport_code_csv_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_demographics_df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"City\", \"city\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"State\", \"state\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Median Age\", \"median_age\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Male Population\", \"male_population\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Female Population\", \"female_population\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Total Population\", \"total_population\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Number of Veterans\", \"number_of_veterans\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Foreign-born\", \"foreign_born\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Average Household Size\", \"average_household_size\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"State Code\", \"state_code\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Race\", \"race\")\n",
    "us_cities_demographics_df_spark = us_cities_demographics_df_spark.withColumnRenamed(\"Count\", \"count\")\n",
    "\n",
    "us_cities_demographics_df_spark.write.parquet(os.path.join(output_path,'us_cities_demographics_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_data_sample_df_spark.write.parquet(os.path.join(output_path,'immigration_data_sample_df_spark'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#read parquest data\n",
    "output_path = 'parquet_output/'\n",
    "airport_code_csv_df_spark = spark.read.parquet(os.path.join(output_path,'airport_code_csv_df_spark'))\n",
    "us_cities_demographics_df_spark = spark.read.parquet(os.path.join(output_path,'us_cities_demographics_df_spark'))\n",
    "immigration_data_sample_df_spark = spark.read.parquet(os.path.join(output_path,'immigration_data_sample_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_code_csv_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_cities_demographics_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_sample_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "# clean immigration_data_sample_df_spark\n",
    "immigration_data_sample_df_spark_clean = immigration_data_sample_df_spark.na.fill({'_c0': 0.0, 'i94port': 0.0,'i94mode': 0.0, 'i94addr': 'NULL_VALUE','depdate': 0.0, 'i94bir': 'NULL_VALUE', \\\n",
    "                        'i94visa': 0.0, 'count': 0.0, 'dtadfile': 'NULL_VALUE', 'visapost': 'NULL_VALUE', \\\n",
    "                        'occup': 'NULL_VALUE', 'entdepa': 'NULL_VALUE', 'entdepd': 'NULL_VALUE', 'entdepu': 'NULL_VALUE', \\\n",
    "                        'matflag': 'NULL_VALUE', 'biryear': 0.0, 'dtaddto': 'NULL_VALUE', 'gender': 'NULL_VALUE', \\\n",
    "                        'insnum': 'NULL_VALUE', 'airline': 'NULL_VALUE', 'admnum': 0.0, 'fltno': 'NULL_VALUE', 'visatype': 'NULL_VALUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_data_sample_df_spark_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+\n",
      "|_c0    |cicid    |i94yr |i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost  |occup     |entdepa|entdepd|entdepu   |matflag|biryear|dtaddto |gender|insnum    |airline|admnum       |fltno|visatype|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+\n",
      "|2027561|4084316.0|2016.0|4.0   |209.0 |209.0 |HHW    |20566.0|1.0    |HI     |20573.0|61.0  |2.0    |1.0  |20160422|NULL_VALUE|NULL_VALUE|G      |O      |NULL_VALUE|M      |1955.0 |07202016|F     |NULL_VALUE|JL     |56582674633.0|00782|WT      |\n",
      "|2171295|4422636.0|2016.0|4.0   |582.0 |582.0 |MCA    |20567.0|1.0    |TX     |20568.0|26.0  |2.0    |1.0  |20160423|MTR       |NULL_VALUE|G      |R      |NULL_VALUE|M      |1990.0 |10222016|M     |NULL_VALUE|*GA    |94361995930.0|XBLNG|B2      |\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_sample_df_spark_clean.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.1 create admissions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- admission_id: string (nullable = false)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- age: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      "\n",
      "+-------------+------------+---+------+\n",
      "| admission_id|country_code|age|gender|\n",
      "+-------------+------------+---+------+\n",
      "|  721095085.0|       692.0|1.0|     F|\n",
      "|55972037033.0|       108.0|1.0|     M|\n",
      "|93323727930.0|       687.0|1.0|     M|\n",
      "|24292172827.0|       276.0|1.0|     M|\n",
      "|92539917330.0|       692.0|1.0|     M|\n",
      "+-------------+------------+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "# Create admissions table\n",
    "immigration_data_sample_df_spark_clean.createOrReplaceTempView(\"admissions\")\n",
    "admissions_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT admnum   AS admission_id,\n",
    "                     i94res   AS country_code, \n",
    "                     i94bir   AS age, \n",
    "                     gender   AS gender\n",
    "    FROM admissions\n",
    "    ORDER BY age ASC\n",
    "\"\"\")\n",
    "admissions_table.printSchema()\n",
    "admissions_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "admissions_table.write.parquet(os.path.join(output_path,'admissions_table_df_spark'))\n",
    "admissions_table_df_spark = spark.read.parquet(os.path.join(output_path,'admissions_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- admission_id: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+-------------+------------+----+------+\n",
      "| admission_id|country_code| age|gender|\n",
      "+-------------+------------+----+------+\n",
      "|59501691433.0|       103.0|34.0|     M|\n",
      "|56357999633.0|       438.0|34.0|     F|\n",
      "+-------------+------------+----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "admissions_table_df_spark.printSchema()\n",
    "admissions_table_df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.2 create us_airports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      "\n",
      "+--------------------+----------+-----------+\n",
      "|        airport_name|state_code|iso_country|\n",
      "+--------------------+----------+-----------+\n",
      "|\"Fly \"\"N\"\" K Airp...|        AR|         US|\n",
      "|\"Holict \"\"Private...|        TX|         US|\n",
      "|\"NJSP - Troop \"\"A...|        NJ|         US|\n",
      "+--------------------+----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create airports table only US airports\n",
    "airport_code_csv_df_spark.createOrReplaceTempView(\"us_airports\")\n",
    "us_airports_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT name   AS airport_name,\n",
    "                     SUBSTRING(iso_region,4)   AS state_code,\n",
    "                     iso_country   AS iso_country\n",
    "    FROM us_airports\n",
    "    WHERE iso_region LIKE 'US%'\n",
    "    ORDER BY airport_name ASC\n",
    "\"\"\")\n",
    "us_airports_table.printSchema()\n",
    "us_airports_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "us_airports_table.write.mode(\"overwrite\").parquet(os.path.join(output_path,'us_airports_table_df_spark'))\n",
    "us_airports_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_airports_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      "\n",
      "+--------------------+----------+-----------+\n",
      "|        airport_name|state_code|iso_country|\n",
      "+--------------------+----------+-----------+\n",
      "|United Ca Bank Da...|        CA|         US|\n",
      "|United Coal Heliport|        VA|         US|\n",
      "+--------------------+----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_airports_table_df_spark.printSchema()\n",
    "us_airports_table_df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.3 create us_city_demographics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      "\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "|   city|     state|state_code|median_age|male_population|female_population|total_population|\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "|Abilene|     Texas|        TX|      31.3|          65212|            60664|          125876|\n",
      "|  Akron|      Ohio|        OH|      38.1|          96886|           100667|          197553|\n",
      "|Alafaya|   Florida|        FL|      33.5|          39504|            45760|           85264|\n",
      "|Alameda|California|        CA|      41.4|          37747|            40867|           78614|\n",
      "| Albany|  New York|        NY|      32.8|          47627|            50825|           98452|\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create admissions table\n",
    "us_cities_demographics_df_spark.createOrReplaceTempView(\"us_city_demographics\")\n",
    "us_city_demographics_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT city   AS city,\n",
    "                     state   AS state, \n",
    "                     state_code   AS state_code, \n",
    "                     median_age   AS median_age,\n",
    "                     male_population   AS male_population,\n",
    "                     female_population   AS female_population,\n",
    "                     total_population   AS total_population\n",
    "    FROM us_city_demographics\n",
    "    ORDER BY city ASC\n",
    "\"\"\")\n",
    "us_city_demographics_table.printSchema()\n",
    "us_city_demographics_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "us_city_demographics_table.write.parquet(os.path.join(output_path,'us_city_demographics_table_df_spark'))\n",
    "us_city_demographics_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_city_demographics_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      "\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "|   city|     state|state_code|median_age|male_population|female_population|total_population|\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "|Atlanta|   Georgia|        GA|      33.8|         223960|           239915|          463875|\n",
      "| Auburn|Washington|        WA|      37.1|          36837|            39743|           76580|\n",
      "+-------+----------+----------+----------+---------------+-----------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_city_demographics_table_df_spark.printSchema()\n",
    "us_city_demographics_table_df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.4 create arrival_time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(types_.TimestampType())\n",
    "def convert_to_timestamp(days):\n",
    "    start_ = datetime(1960,1,1)\n",
    "    print(days)\n",
    "    duration = timedelta(days=int(float(days)))\n",
    "    return (start_+duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp = convert_to_timestamp(immigration_data_sample_df_spark.arrdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create arrival time table\n",
    "immigration_data_sample_df_spark_clean = immigration_data_sample_df_spark_clean.withColumn(\"arrival_time\", convert_to_timestamp(immigration_data_sample_df_spark.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       arrival_time|\n",
      "+-------------------+\n",
      "|2016-04-22 00:00:00|\n",
      "|2016-04-23 00:00:00|\n",
      "|2016-04-07 00:00:00|\n",
      "|2016-04-28 00:00:00|\n",
      "|2016-04-06 00:00:00|\n",
      "|2016-04-08 00:00:00|\n",
      "|2016-04-12 00:00:00|\n",
      "|2016-04-02 00:00:00|\n",
      "|2016-04-28 00:00:00|\n",
      "|2016-04-01 00:00:00|\n",
      "|2016-04-07 00:00:00|\n",
      "|2016-04-27 00:00:00|\n",
      "|2016-04-15 00:00:00|\n",
      "|2016-04-26 00:00:00|\n",
      "|2016-04-08 00:00:00|\n",
      "|2016-04-01 00:00:00|\n",
      "|2016-04-06 00:00:00|\n",
      "|2016-04-13 00:00:00|\n",
      "|2016-04-24 00:00:00|\n",
      "|2016-04-14 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_sample_df_spark_clean.select(\"arrival_time\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- arrival_time: timestamp (nullable = true)\n",
      " |-- arrival_hour: integer (nullable = true)\n",
      " |-- arrival_day: integer (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      "\n",
      "+-------------------+------------+-----------+-------------+------------+\n",
      "|arrival_time       |arrival_hour|arrival_day|arrival_month|arrival_year|\n",
      "+-------------------+------------+-----------+-------------+------------+\n",
      "|2016-04-01 00:00:00|0           |1          |4            |2016        |\n",
      "|2016-04-26 00:00:00|0           |26         |4            |2016        |\n",
      "|2016-04-02 00:00:00|0           |2          |4            |2016        |\n",
      "|2016-04-05 00:00:00|0           |5          |4            |2016        |\n",
      "|2016-04-07 00:00:00|0           |7          |4            |2016        |\n",
      "+-------------------+------------+-----------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_sample_df_spark_clean.createOrReplaceTempView(\"arrival_time\")\n",
    "arrival_time_table = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT  arrival_time           AS arrival_time, \n",
    "                     hour(arrival_time)       AS arrival_hour, \n",
    "                     day(arrival_time)        AS arrival_day, \n",
    "                     month(arrival_time)      AS arrival_month,\n",
    "                     year(arrival_time)       AS arrival_year\n",
    "    FROM arrival_time\n",
    "\"\"\")\n",
    "arrival_time_table.printSchema()\n",
    "arrival_time_table.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_time_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "arrival_time_table.write.parquet(os.path.join(output_path,'arrival_time_table_df_spark'))\n",
    "arrival_time_table_df_spark = spark.read.parquet(os.path.join(output_path,'arrival_time_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Join us city demographics with airports\n",
    "# us_city_df_spark_joined = us_city_demographics_table_df_spark.join(us_airports_table_df_spark, ['state_code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485916"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# us_city_df_spark_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      "\n",
      "+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "|state_code|     city|     state|median_age|male_population|female_population|total_population|        airport_name|iso_country|\n",
      "+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "|        CA|Yuba City|California|      34.5|          33654|            33290|           66944|United Ca Bank Da...|         US|\n",
      "|        CA| Whittier|California|      36.1|          44397|            43039|           87436|United Ca Bank Da...|         US|\n",
      "+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# us_city_df_spark_joined.printSchema()\n",
    "# us_city_df_spark_joined.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # join immigrations with us city above\n",
    "# us_immigrations_df_spark_joined = immigration_data_sample_df_spark_clean.join(us_city_df_spark_joined,\n",
    "#                                                                              immigration_data_sample_df_spark_clean.i94addr == us_city_df_spark_joined.state_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = false)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = false)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = false)\n",
      " |-- i94addr: string (nullable = false)\n",
      " |-- depdate: string (nullable = false)\n",
      " |-- i94bir: string (nullable = false)\n",
      " |-- i94visa: string (nullable = false)\n",
      " |-- count: string (nullable = false)\n",
      " |-- dtadfile: string (nullable = false)\n",
      " |-- visapost: string (nullable = false)\n",
      " |-- occup: string (nullable = false)\n",
      " |-- entdepa: string (nullable = false)\n",
      " |-- entdepd: string (nullable = false)\n",
      " |-- entdepu: string (nullable = false)\n",
      " |-- matflag: string (nullable = false)\n",
      " |-- biryear: string (nullable = false)\n",
      " |-- dtaddto: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- insnum: string (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- admnum: string (nullable = false)\n",
      " |-- fltno: string (nullable = false)\n",
      " |-- visatype: string (nullable = false)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      "\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+----------+----------+-------+-------------+-----+--------+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "|    _c0|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|  visapost|     occup|entdepa|entdepd|   entdepu|matflag|biryear| dtaddto|    gender|    insnum|airline|       admnum|fltno|visatype|state_code|     city|     state|median_age|male_population|female_population|total_population|        airport_name|iso_country|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+----------+----------+-------+-------------+-----+--------+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "|1920712|3874218.0|2016.0|   4.0| 148.0| 112.0|    SFR|20565.0|    1.0|     CA|20582.0|  49.0|    2.0|  1.0|20160421|NULL_VALUE|NULL_VALUE|      O|      O|NULL_VALUE|      M| 1967.0|07192016|NULL_VALUE|NULL_VALUE|     LH|56534271933.0|00454|      WT|        CA|Yuba City|California|      34.5|          33654|            33290|           66944|United Ca Bank Da...|         US|\n",
      "| 697642|1407986.0|2016.0|   4.0| 245.0| 245.0|    SFR|20552.0|    1.0|     CA|20566.0|  60.0|    2.0|  1.0|20160408|       BEJ|NULL_VALUE|      G|      O|NULL_VALUE|      M| 1956.0|10072016|         M|NULL_VALUE|     MU|93032766930.0|00589|      B2|        CA|Yuba City|California|      34.5|          33654|            33290|           66944|United Ca Bank Da...|         US|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+----------+----------+-------+-------------+-----+--------+----------+---------+----------+----------+---------------+-----------------+----------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# us_immigrations_df_spark_joined.printSchema()\n",
    "# us_immigrations_df_spark_joined.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# us_immigrations_df_spark_joined=us_immigrations_df_spark_joined.withColumn(\"immigration_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# us_immigrations_df_spark_joined.printSchema()\n",
    "# us_immigrations_df_spark_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# join immigrations with us city above\n",
    "us_immigrations_df_spark_joined = immigration_data_sample_df_spark_clean.join(arrival_time_table_df_spark, ['arrival_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+------------+-----------+-------------+------------+\n",
      "|       arrival_time|    _c0|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|  visapost|     occup|entdepa|entdepd|   entdepu|matflag|biryear| dtaddto|gender|    insnum|airline|       admnum|fltno|visatype|arrival_hour|arrival_day|arrival_month|arrival_year|\n",
      "+-------------------+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+------------+-----------+-------------+------------+\n",
      "|2016-04-22 00:00:00|2027561|4084316.0|2016.0|   4.0| 209.0| 209.0|    HHW|20566.0|    1.0|     HI|20573.0|  61.0|    2.0|  1.0|20160422|NULL_VALUE|NULL_VALUE|      G|      O|NULL_VALUE|      M| 1955.0|07202016|     F|NULL_VALUE|     JL|56582674633.0|00782|      WT|           0|         22|            4|        2016|\n",
      "+-------------------+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+----------+----------+-------+-------+----------+-------+-------+--------+------+----------+-------+-------------+-----+--------+------------+-----------+-------------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_immigrations_df_spark_joined.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_immigrations_df_spark_joined.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.5 create us_immigrations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_immigrations_df_spark_joined=us_immigrations_df_spark_joined.withColumn(\"immigration_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- immigration_id: long (nullable = false)\n",
      " |-- state_code: string (nullable = false)\n",
      " |-- admission_id: string (nullable = false)\n",
      " |-- air_line: string (nullable = false)\n",
      " |-- flight_number: string (nullable = false)\n",
      " |-- arrival_time: timestamp (nullable = true)\n",
      " |-- departure_date: string (nullable = false)\n",
      " |-- birth_year: string (nullable = false)\n",
      "\n",
      "+--------------+----------+-------------+--------+-------------+-------------------+--------------+----------+\n",
      "|immigration_id|state_code| admission_id|air_line|flight_number|       arrival_time|departure_date|birth_year|\n",
      "+--------------+----------+-------------+--------+-------------+-------------------+--------------+----------+\n",
      "|           777|        NV|55463158833.0|      BA|        00275|2016-04-01 00:00:00|       20553.0|    1981.0|\n",
      "|           791|NULL_VALUE|44162582033.0|      MU|        00763|2016-04-01 00:00:00|       20550.0|    1986.0|\n",
      "+--------------+----------+-------------+--------+-------------+-------------------+--------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create admissions table\n",
    "us_immigrations_df_spark_joined.createOrReplaceTempView(\"us_immigrations\")\n",
    "us_immigrations_table = spark.sql(\"\"\"\n",
    "    SELECT  DISTINCT immigration_id   AS immigration_id,\n",
    "                     i94addr   AS state_code, \n",
    "                     admnum   AS admission_id, \n",
    "                     airline   AS air_line,\n",
    "                     fltno   AS flight_number,\n",
    "                     arrival_time   AS arrival_time,\n",
    "                     depdate   AS departure_date,\n",
    "                     biryear   AS birth_year\n",
    "    FROM us_immigrations\n",
    "    ORDER BY arrival_time\n",
    "\"\"\")\n",
    "us_immigrations_table.printSchema()\n",
    "us_immigrations_table.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_immigrations_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "us_immigrations_table.write.mode(\"overwrite\").parquet(os.path.join(output_path,'us_immigrations_table_df_spark'))\n",
    "us_immigrations_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_immigrations_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- immigration_id: long (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- admission_id: string (nullable = true)\n",
      " |-- air_line: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- arrival_time: timestamp (nullable = true)\n",
      " |-- departure_date: string (nullable = true)\n",
      " |-- birth_year: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_immigrations_table_df_spark.printSchema()\n",
    "us_immigrations_table_df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "admissions_table_df_spark = spark.read.parquet(os.path.join(output_path,'admissions_table_df_spark'))\n",
    "us_airports_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_airports_table_df_spark'))\n",
    "us_city_demographics_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_city_demographics_table_df_spark'))\n",
    "arrival_time_table_df_spark = spark.read.parquet(os.path.join(output_path,'arrival_time_table_df_spark'))\n",
    "us_immigrations_table_df_spark = spark.read.parquet(os.path.join(output_path,'us_immigrations_table_df_spark'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "quality_results = {\n",
    "    'admissions':{'count_record':0, 'count_null':0, 'quality_check':\"Not checked yet\"},\n",
    "    'airports':{'count_record':0, 'count_null':0, 'quality_check':\"Not checked yet\"},\n",
    "    'us_city_demographics':{'count_record':0, 'count_null':0, 'quality_check':\"Not checked yet\"},\n",
    "    'arrival_time':{'count_record':0, 'count_null':0, 'quality_check':\"Not checked yet\"},\n",
    "    'immigrations':{'count_record':0, 'count_null':0, 'quality_check':\"Not checked yet\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.1 check admissions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "admissions_table_df_spark.createOrReplaceTempView(\"admissions_table\")\n",
    "admissions_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM admissions_table\n",
    "    WHERE admission_id IS NULL OR admission_id == \"\"\n",
    "\"\"\")\n",
    "result1 = admissions_check.collect()[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "admissions_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "admissions_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM admissions_table\n",
    "\"\"\")\n",
    "result2 = admissions_check.collect()[0][0] \n",
    "admissions_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_quality(table_name,quality_results, result1, result2):\n",
    "    print('count_null: ', result1)\n",
    "    print('count_record: ', result2)\n",
    "    quality_results[table_name]['count_null'] = result1\n",
    "    quality_results[table_name]['count_record'] = result2\n",
    "    if result1 == 0 and result2 > 0:\n",
    "        quality_results[table_name]['quality_check'] = 'GOOD'\n",
    "    else:\n",
    "        quality_results[table_name]['quality_check'] = 'NOT GOOD'\n",
    "        \n",
    "    return quality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_null:  0\n",
      "count_record:  1000\n"
     ]
    }
   ],
   "source": [
    "quality_results = check_quality('admissions', quality_results, result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.2 check us_airports table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_null:  0\n",
      "count_record:  22608\n"
     ]
    }
   ],
   "source": [
    "us_airports_table_df_spark.createOrReplaceTempView(\"us_airports_table\")\n",
    "us_airports_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_airports_table\n",
    "    WHERE airport_name IS NULL OR airport_name == \"\"\n",
    "\"\"\")\n",
    "result1 = us_airports_check.collect()[0][0] \n",
    "us_airports_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_airports_table\n",
    "\"\"\")\n",
    "result2 = us_airports_check.collect()[0][0] \n",
    "quality_results = check_quality('airports', quality_results, result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.3 check us_city_demographics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_null:  0\n",
      "count_record:  596\n"
     ]
    }
   ],
   "source": [
    "us_city_demographics_table_df_spark.createOrReplaceTempView(\"us_city_demographics_table\")\n",
    "us_city_demographics_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_city_demographics_table\n",
    "    WHERE city IS NULL OR city == \"\"\n",
    "\"\"\")\n",
    "result1 = us_city_demographics_check.collect()[0][0] \n",
    "us_city_demographics_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_city_demographics_table\n",
    "\"\"\")\n",
    "result2 = us_city_demographics_check.collect()[0][0] \n",
    "quality_results = check_quality('us_city_demographics', quality_results, result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.4 check arrival_time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_null:  0\n",
      "count_record:  30\n"
     ]
    }
   ],
   "source": [
    "arrival_time_table_df_spark.createOrReplaceTempView(\"arrival_time_table\")\n",
    "arrival_time_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM arrival_time_table\n",
    "    WHERE arrival_time IS NULL OR arrival_time == \"\"\n",
    "\"\"\")\n",
    "result1 = arrival_time_check.collect()[0][0] \n",
    "arrival_time_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM arrival_time_table\n",
    "\"\"\")\n",
    "result2 = arrival_time_check.collect()[0][0] \n",
    "quality_results = check_quality('arrival_time', quality_results, result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.5 check us_immigrations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_null:  0\n",
      "count_record:  1000\n"
     ]
    }
   ],
   "source": [
    "us_immigrations_table_df_spark.createOrReplaceTempView(\"us_immigrations_table\")\n",
    "us_immigrations_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_immigrations_table\n",
    "    WHERE immigration_id IS NULL OR immigration_id == \"\" OR\n",
    "          admission_id IS NULL OR admission_id == \"\" OR\n",
    "          state_code IS NULL OR state_code == \"\" OR\n",
    "          arrival_time IS NULL OR arrival_time == \"\"\n",
    "\"\"\")\n",
    "result1 = us_immigrations_check.collect()[0][0] \n",
    "us_immigrations_check = spark.sql(\"\"\"\n",
    "    SELECT COUNT(1)\n",
    "    FROM us_immigrations_table\n",
    "\"\"\")\n",
    "result2 = us_immigrations_check.collect()[0][0] \n",
    "quality_results = check_quality('immigrations', quality_results, result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### results of checking quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admissions': {'count_record': 1000,\n",
       "  'count_null': 0,\n",
       "  'quality_check': 'GOOD'},\n",
       " 'airports': {'count_record': 22608, 'count_null': 0, 'quality_check': 'GOOD'},\n",
       " 'us_city_demographics': {'count_record': 596,\n",
       "  'count_null': 0,\n",
       "  'quality_check': 'GOOD'},\n",
       " 'arrival_time': {'count_record': 30,\n",
       "  'count_null': 0,\n",
       "  'quality_check': 'GOOD'},\n",
       " 'immigrations': {'count_record': 1000,\n",
       "  'count_null': 0,\n",
       "  'quality_check': 'GOOD'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Data dictionary for this project is described in described_dictionary.json file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.1 Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "- I use Pandas and Spark in Python, because it have many libraries to read, write, clean, process data\n",
    "- These libraries are easy to use, have many special documents on Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 Propose how often the data should be updated and why.\n",
    "- In this project, dataset was limited. So, i use local storage to store input and outpu data\n",
    "- When dataset is greater than, we can use AWS S3 instead to avoid extra costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3 Write a description of how you would approach the problem differently under the following scenarios:\n",
    "- The data was increased by 100x\n",
    "    - Input and output data should be stored in AWS S3, because it can scale according to need\n",
    "    - Spark Cluster should be used to process parallel\n",
    "    - Database should use AWS RDS\n",
    "- The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "    - ETL should be only process changed information (input, output) to optimize processing\n",
    "    - Output data should be stored AWS RDS and have backup plans to make it available all time\n",
    "- The database needed to be accessed by 100+ people\n",
    "    - Output data should be stored AWS RDS and have backup plans to make it available all time\n",
    "    - Create many replicas and use loadbalancer to balance query processing \n",
    "    - Store results of complex queries which take time for faster response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
